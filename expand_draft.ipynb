{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this first\n",
    "#imports\n",
    "import pandas as pd\n",
    "\n",
    "class allisort():  \n",
    "    def __init__(self, fileIn, keys, values , file_out = False, merge = {}, nan = 5,col = False, add = False):\n",
    "        '''\n",
    "        fileIn: (required) file to open. MUST be csv\n",
    "        key: [\"ColumnName_1\", \"ColumnName_2, ... , \"ColumnName_N\"] List of strings. Will be column headers\n",
    "            ColumnName_1 will hold the names of the expanded values (Names of Columns specified in values)\n",
    "            ColumnName)_N is the last column, will hold the values under the Corresponding columnName_1\n",
    "            ColumnName_2 to ColumnName_(N-1),please specify these if you specified anything in \"add\"\n",
    "        values: [int, int, ... , int] List of ints; Columns in the original Data Frame to expand\n",
    "        col: (optional) int. If column names are on a different line, specify the line\n",
    "        #????? merge: (optional) [] array of files to merge with file_name. Useful if there are multiple files to merge\n",
    "        nan: (Optional) int. Minimum number of filled cells before row is deleted\n",
    "        file_out: (optional) file to write out to. If none are specified then will just re-write fileIn\n",
    "        add: (optional) {\"letter(s)\":[column int(s)], \"\":[],...\"\":[]} Dictionary of letters to arrays. Defines if specific modifiers need to be added to a column, ie units\n",
    "        '''\n",
    "        \n",
    "        self.f = pd.read_csv(fileIn)\n",
    "        self.f = self.f.loc[:, ~self.f.columns.str.contains('^Unnamed')] #deletes unnamed/blank columns\n",
    "        self.splitOn = \"|\"\n",
    "        self.fileIn = fileIn\n",
    "        #Rename columns if needed\n",
    "        if type(col) == int:\n",
    "            self.f.columns = self.f.iloc[col,]\n",
    "            for i in range(col+1):\n",
    "                self.f = self.f.drop([i,])\n",
    "        #Define file name to output to\n",
    "        self.outFile = self.setOutputFilename(file_out)\n",
    "        \n",
    "        #Changes column names if a dict was entered for add\n",
    "        self.add_to_col(add)\n",
    "            \n",
    "        self.DF = self.expandDF(key, values, self.f)\n",
    "        \n",
    "        #merges DF\n",
    "        self.DF = self.mergeDF(merge)\n",
    "        self.DF.to_csv(self.outFile, index=False)\n",
    "    \n",
    "    \"\"\"Adds the key of a dict to the int values defined for it \"\"\"\n",
    "    def add_to_col(self, add):\n",
    "        l = list(self.f.columns)\n",
    "        if type(add) == dict:\n",
    "            for key, value in add.items():\n",
    "                for i in value:\n",
    "                    if i in range(len(l)):\n",
    "                        l[i] += \"|%s\"%(str(key))\n",
    "                    else:\n",
    "                        print(l)\n",
    "                        print(\"{0} in key {1} is not a recognized value! What would you like to do? Skip it = S; Exit = E\".format(i, key))\n",
    "                        a = input().upper()\n",
    "                        while a != \"E\" and a != \"S\":\n",
    "                            print(\"{0} is not a valid command!\\nTo exit and try again, enter \\\"E\\\"\\nTo skip it, enter \\\"S\\\"\".format(a))\n",
    "                            a = input().upper()\n",
    "                        if a == \"E\":\n",
    "                            return False\n",
    "                        \n",
    "        elif type(add) == str:\n",
    "            self.sepOn = add\n",
    "                    \n",
    "        self.f.columns = l\n",
    "    \n",
    "    \"\"\"Input a dict of {table_name:column_to_merge_on}\"\"\"\n",
    "    def mergeDF(self, dic):\n",
    "        for key, value in dic.items():\n",
    "            new = pd.read_csv(key)\n",
    "            print(new.head(5))\n",
    "            self.DF = self.DF.merge(new,how = 'left', on = value )\n",
    "        return self.DF\n",
    "    \n",
    "    \"\"\"Input a string, outputs a file name for a csv file\"\"\"\n",
    "    def setOutputFilename(self, file_out):\n",
    "        #Define file name to output to\n",
    "        outFile = \"\"\n",
    "        if type(file_out) == bool: #if False use the fileIn name, but save it to the current directory (deletes everything before the last \"/\")\n",
    "            outFile = self.fileIn\n",
    "            if \"/\" in outFile: #Ensures it is saved to current directory, unless \"/\" is used then good luck\n",
    "                outFile = outFile.split(\"/\")\n",
    "                outFile = outFile[len(outFile)-1]\n",
    "                outFile = ''.join(outFile)\n",
    "            outFile = \"output_\" + outFile\n",
    "        else:\n",
    "            outFile = file_out\n",
    "        #Ensures that file ends with a .csv. Deletes anyting after the first \".\"\n",
    "        outFile = outFile.split(\".\")\n",
    "        if len(outFile) > 1:\n",
    "            outFile = outFile[:len(outFile)-1]\n",
    "        outFile = ''.join(outFile)\n",
    "        outFile += \".csv\" \n",
    "        return outFile\n",
    "    \n",
    "    \"\"\"Actually expands the data frame based on the key and values\"\"\"\n",
    "    def expandDF(self, key, values, f):\n",
    "        df = f.copy()\n",
    "        c = list(df.columns)\n",
    "        #Change from intarray to stringarray. Allows for modifications\n",
    "        names = [] #analyte names\n",
    "        for i in values:\n",
    "            if type(i) == int:\n",
    "                try: \n",
    "                    names.append(c[i])\n",
    "                except:\n",
    "                    print(i)\n",
    "            elif i in c: #allows for functionality with actually specifying names\n",
    "                names.append(i)        \n",
    "        #Keeps only the columns not specified for expansion\n",
    "        for n in names:    \n",
    "            if n in c:\n",
    "                c.remove(n)\n",
    "        #Creat a temp for the output\n",
    "        temp = pd.DataFrame(columns = c)\n",
    "        #Add columns according to the column names specified in Key\n",
    "        for k in key:\n",
    "            temp[k] = None\n",
    "        \n",
    "        #Expands each row by analyte in Names\n",
    "        for i in range(len(df.iloc[:,0])):\n",
    "            y = {}#Holds the values that are kept the same when expanding the row\n",
    "            #Adds those values here\n",
    "            for x in c:\n",
    "                y[x] = (df.iloc[i][x])\n",
    "            #Fore each we expand upon\n",
    "            for analyte in names:\n",
    "                other = y.copy() #New dict that is copy of y\n",
    "                a = analyte.split(self.splitOn) #Split analyte by |, incase we used the add argument\n",
    "                \n",
    "                #This part adds columns if there weren't enough\n",
    "                st = 0\n",
    "                while len(key) < len(a)+1:\n",
    "                    key.append(\"Allisort_Val_\"+ str(st))\n",
    "                    st += 1\n",
    "                    \n",
    "                #adds the values to the appropriate place in the dictionary\n",
    "                for k in range(len(key)):\n",
    "                    if k < len(a):\n",
    "                        other[key[k]] = a[k]\n",
    "                    else:\n",
    "                        other[key[k]] = df.iloc[i][analyte]\n",
    "                        \n",
    "                temp = temp.append(other, ignore_index=True)#adds to temp\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to expand it here\n",
    "\n",
    "file = \"Core Sample Results.csv\"\n",
    "key = [\"Analyte\", \"Units\", \"Value\"]\n",
    "value = list(range(7,31))\n",
    "add = \" \"\n",
    "\n",
    "\n",
    "sort = allisort(file, key, value, add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n"
     ]
    }
   ],
   "source": [
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Station Lab Sample ID Field ID Reach Sample Type 1  \\\n",
      "0    1-B1     CERC 01 2   UCR-01    R1          Test   \n",
      "1    1-B2     CERC 02 2   UCR-02    R1          Test   \n",
      "2    1-B4     CERC 05 2   UCR-05    R1          Test   \n",
      "3    1-B5     CERC 04 2   UCR-04    R1          Test   \n",
      "4    1-B6     CERC 03 2   UCR-03    R1          Test   \n",
      "\n",
      "   Sampling Coordinates (UTM Zone 11: Easting)  \\\n",
      "0                                     453261.0   \n",
      "1                                     451735.0   \n",
      "2                                     445689.0   \n",
      "3                                     446376.0   \n",
      "4                                     446353.0   \n",
      "\n",
      "   Sampling Coordinates (UTM Zone 11: Northing) Field Sampling Date  \\\n",
      "0                                     5427310.0            5-Sep-13   \n",
      "1                                     5424015.0            5-Sep-13   \n",
      "2                                     5420817.0            5-Sep-13   \n",
      "3                                     5421101.0            5-Sep-13   \n",
      "4                                     5421016.0            5-Sep-13   \n",
      "\n",
      "  Sample Depth (range in inches from surface)  \n",
      "0                                         0-4  \n",
      "1                                         0-4  \n",
      "2                                         0-4  \n",
      "3                                         0-4  \n",
      "4                                         0-4  \n"
     ]
    }
   ],
   "source": [
    "file = \"Phase 2 pg1.csv\"\n",
    "key = [\"Analyte\", \"Units\", \"Value\"]\n",
    "val = list(range(4,26))\n",
    "add = {\"%\":list(range(4,16)), \"(mg/kg)\":list(range(16,26))}\n",
    "m = {\"Phase 2 pg2.csv\":[\"Station\",\"Lab Sample ID\",\"Field ID\"]}\n",
    "\n",
    "s2 = allisort(file, key, val, merge = m, add = add)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
